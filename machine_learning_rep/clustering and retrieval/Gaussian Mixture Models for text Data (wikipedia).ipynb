{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.stats import multivariate_normal\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv(\"people_wiki.csv\").head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                 name  \\\n",
       "0        <http://dbpedia.org/resource/Digby_Morrell>        Digby Morrell   \n",
       "1       <http://dbpedia.org/resource/Alfred_J._Lewy>       Alfred J. Lewy   \n",
       "2        <http://dbpedia.org/resource/Harpdog_Brown>        Harpdog Brown   \n",
       "3  <http://dbpedia.org/resource/Franz_Rottensteiner>  Franz Rottensteiner   \n",
       "4               <http://dbpedia.org/resource/G-Enka>               G-Enka   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2  harpdog brown is a singer and harmonica player...  \n",
       "3  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    \n",
    "    return csr_matrix( (data, indices, indptr), shape)\n",
    "\n",
    "tf_idf = load_sparse_csr('4_tf_idf.npz')  #5000x100282 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3)\n",
      "(5000, 100282)\n"
     ]
    }
   ],
   "source": [
    "print(wiki.shape)\n",
    "print(tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100282, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sundayswadsworth</td>\n",
       "      <td>37318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verplank</td>\n",
       "      <td>46431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damfunk</td>\n",
       "      <td>23253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anyer</td>\n",
       "      <td>62437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonja</td>\n",
       "      <td>37922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  index\n",
       "0  sundayswadsworth  37318\n",
       "1          verplank  46431\n",
       "2           damfunk  23253\n",
       "3             anyer  62437\n",
       "4             sonja  37922"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dict mapping indices to words\n",
    "with open(\"4_map_index_to_word.json\") as json_file:  \n",
    "    map_index_to_word = json.load(json_file)  # size = 100282\n",
    "\n",
    "map_index_to_word = pd.DataFrame(list(map_index_to_word.items()), columns = ['category', 'index'])\n",
    "print(map_index_to_word.shape)\n",
    "map_index_to_word.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features - ie tf-idf representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = normalize(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - EM with k-means initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag(array):\n",
    "    n = len(array)\n",
    "    return spdiags(array, 0, n, n)\n",
    "\n",
    "def logpdf_diagonal_gaussian(x, mean, cov):\n",
    "    '''\n",
    "    Compute logpdf of a multivariate Gaussian distribution with diagonal covariance at a given point x.\n",
    "    A multivariate Gaussian distribution with a diagonal covariance is equivalent\n",
    "    to a collection of independent Gaussian random variables.\n",
    "\n",
    "    x should be a sparse matrix. The logpdf will be computed for each row of x.\n",
    "    mean and cov should be given as 1D numpy arrays\n",
    "    mean[i] : mean of i-th variable\n",
    "    cov[i] : variance of i-th variable'''\n",
    "\n",
    "    n = x.shape[0]\n",
    "    dim = x.shape[1]\n",
    "    assert(dim == len(mean) and dim == len(cov))\n",
    "\n",
    "    # multiply each i-th column of x by (1/(2*sigma_i)), where sigma_i is sqrt of variance of i-th variable.\n",
    "    scaled_x = x.dot( diag(1./(2*np.sqrt(cov))) )\n",
    "    # multiply each i-th entry of mean by (1/(2*sigma_i))\n",
    "    scaled_mean = mean/(2*np.sqrt(cov))\n",
    "\n",
    "    # sum of pairwise squared Eulidean distances gives SUM[(x_i - mean_i)^2/(2*sigma_i^2)]\n",
    "    return -np.sum(np.log(np.sqrt(2*np.pi*cov))) - pairwise_distances(scaled_x, [scaled_mean], 'euclidean').flatten()**2\n",
    "\n",
    "\n",
    "\n",
    "def log_sum_exp(x, axis):\n",
    "    '''Compute the log of a sum of exponentials'''\n",
    "    x_max = np.max(x, axis=axis)\n",
    "    if axis == 1:\n",
    "        return x_max + np.log( np.sum(np.exp(x-x_max[:,np.newaxis]), axis=1) )\n",
    "    else:\n",
    "        return x_max + np.log( np.sum(np.exp(x-x_max), axis=0) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_for_high_dimension(data, means, covs, weights, cov_smoothing=1e-5, maxiter=int(1e3), thresh=1e-4, verbose=False):\n",
    "    # cov_smoothing: specifies the default variance assigned to absent features in a cluster.\n",
    "    #                If we were to assign zero variances to absent features, we would be overconfient,\n",
    "    #                as we hastily conclude that those featurese would NEVER appear in the cluster.\n",
    "    #                We'd like to leave a little bit of possibility for absent features to show up later.\n",
    "    n = data.shape[0]\n",
    "    dim = data.shape[1]\n",
    "    mu = deepcopy(means)\n",
    "    Sigma = deepcopy(covs)\n",
    "    K = len(mu)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    ll = None\n",
    "    ll_trace = []\n",
    "\n",
    "    for i in range(maxiter):\n",
    "        # E-step: compute responsibilities\n",
    "        logresp = np.zeros((n,K))\n",
    "        for k in range(K):\n",
    "            logresp[:,k] = np.log(weights[k]) + logpdf_diagonal_gaussian(data, mu[k], Sigma[k])\n",
    "        ll_new = np.sum(log_sum_exp(logresp, axis=1))\n",
    "        if verbose:\n",
    "            print(ll_new)\n",
    "        logresp -= np.vstack(log_sum_exp(logresp, axis=1))\n",
    "        resp = np.exp(logresp)\n",
    "        counts = np.sum(resp, axis=0)\n",
    "\n",
    "        # M-step: update weights, means, covariances\n",
    "        weights = counts / np.sum(counts)\n",
    "        for k in range(K):\n",
    "            mu[k] = (diag(resp[:,k]).dot(data)).sum(axis=0)/counts[k]\n",
    "            mu[k] = mu[k].A1\n",
    "\n",
    "            Sigma[k] = diag(resp[:,k]).dot( data.multiply(data)-2*data.dot(diag(mu[k])) ).sum(axis=0) \\\n",
    "                       + (mu[k]**2)*counts[k]\n",
    "            Sigma[k] = Sigma[k].A1 / counts[k] + cov_smoothing*np.ones(dim)\n",
    "\n",
    "        # check for convergence in log-likelihood\n",
    "        ll_trace.append(ll_new)\n",
    "        if ll is not None and (ll_new-ll) < thresh and ll_new > -np.inf:\n",
    "            ll = ll_new\n",
    "            break\n",
    "        else:\n",
    "            ll = ll_new\n",
    "\n",
    "    out = {'weights':weights,'means':mu,'covs':Sigma,'loglik':ll_trace,'resp':resp}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-means for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "num_clusters = 25\n",
    "\n",
    "# Use scikit-learn's k-means to simplify workflow\n",
    "kmeans_model = KMeans(n_clusters=num_clusters, n_init=5, max_iter=400, random_state=1, n_jobs=-1)\n",
    "kmeans_model.fit(tf_idf)\n",
    "centroids, cluster_assignment = kmeans_model.cluster_centers_, kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(100282,)\n"
     ]
    }
   ],
   "source": [
    "means = [centroid for centroid in centroids] # 25 x (100282,)\n",
    "print(len(means))\n",
    "print(means[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = tf_idf.shape[0]\n",
    "weights = []\n",
    "for i in range(num_clusters):\n",
    "    # Compute the number of data points assigned to cluster i:\n",
    "    num_assigned = np.sum(cluster_assignment == i) # YOUR CODE HERE\n",
    "    w = float(num_assigned) / num_docs\n",
    "    weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = []\n",
    "for i in range(num_clusters):\n",
    "    member_rows = tf_idf[cluster_assignment==i]\n",
    "    cov = (member_rows.multiply(member_rows) - 2*member_rows.dot(diag(means[i]))).sum(axis=0).A1 / member_rows.shape[0] \\\n",
    "          + means[i]**2\n",
    "    cov[cov < 1e-8] = 1e-8\n",
    "    covs.append(cov)    # 25 x (100282,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(100282,)\n"
     ]
    }
   ],
   "source": [
    "print(len(covs))\n",
    "print(covs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train EM using initializations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = EM_for_high_dimension(tf_idf, means, covs, weights, cov_smoothing=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3879297479.366981, 4883345753.533131, 4883345753.533131]\n"
     ]
    }
   ],
   "source": [
    "print(out['loglik']) # print history of log-likelihood over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the EM clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_EM_clusters(tf_idf, means, covs, map_index_to_word):\n",
    "    print('')\n",
    "    print('==========================================================')\n",
    "\n",
    "    num_clusters = len(means)\n",
    "    for c in range(num_clusters):\n",
    "        print('Cluster {0:d}: Largest mean parameters in cluster '.format(c))\n",
    "        print('\\n{0: <12}{1: <12}{2: <12}'.format('Word', 'Mean', 'Variance'))\n",
    "        \n",
    "        # The k'th element of sorted_word_ids should be the index of the word \n",
    "        # that has the k'th-largest value in the cluster mean. Hint: Use np.argsort().\n",
    "        sorted_word_ids = np.argsort(means[c])[::-1]  # YOUR CODE HERE\n",
    "\n",
    "        for i in sorted_word_ids[:5]:\n",
    "            print('{0: <12}{1:<10.2e}{2:10.2e}'.format(map_index_to_word['category'][i], \n",
    "                                                       means[c][i],\n",
    "                                                       covs[c][i]))\n",
    "        print('\\n=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "uniface     1.51e-01    1.90e-02\n",
      "resonance   6.33e-02    6.45e-03\n",
      "trevor      5.91e-02    6.36e-03\n",
      "augustseptember4.77e-02    8.72e-03\n",
      "solidi      4.68e-02    3.29e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          1.60e-01    4.59e-03\n",
      "registration1.04e-01    3.20e-03\n",
      "nationalities1.53e-02    1.04e-03\n",
      "isoprenylcysteine1.52e-02    1.14e-03\n",
      "osagie      1.27e-02    7.33e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "deter       7.45e-02    4.57e-03\n",
      "zahida      5.84e-02    2.55e-03\n",
      "cutler      5.72e-02    2.83e-03\n",
      "testingbut  5.06e-02    2.35e-03\n",
      "uncontrollable3.79e-02    9.46e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "gamewhile   5.56e-02    4.00e-03\n",
      "czechoslovakiaforman5.47e-02    4.55e-03\n",
      "mancow      5.04e-02    5.21e-03\n",
      "nazianzenum 3.72e-02    2.46e-03\n",
      "karabakh    3.65e-02    2.07e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "harlow      5.26e-02    5.50e-03\n",
      "taxpayers   4.30e-02    2.38e-03\n",
      "lance       3.87e-02    1.51e-03\n",
      "bastien     3.19e-02    1.57e-03\n",
      "ozark       3.06e-02    3.10e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "nbc         1.59e-01    1.14e-02\n",
      "yearsunsatisfied5.11e-02    1.99e-03\n",
      "19801985on  4.96e-02    6.96e-03\n",
      "uncontrollable4.90e-02    1.42e-03\n",
      "postin      4.81e-02    2.30e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "secgov      5.18e-02    1.08e-02\n",
      "df          4.42e-02    1.36e-02\n",
      "dops        4.31e-02    3.78e-03\n",
      "websiteleeb 3.53e-02    4.77e-03\n",
      "suvero      3.11e-02    6.93e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "knot        1.78e-01    6.05e-03\n",
      "manezh      6.60e-02    3.33e-03\n",
      "mechanicsburg4.46e-02    3.60e-03\n",
      "49member    3.41e-02    1.61e-03\n",
      "boshoff     2.83e-02    1.95e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "livi        1.62e-01    1.65e-02\n",
      "theatersa   1.09e-01    3.10e-02\n",
      "stemmed     3.78e-02    8.97e-03\n",
      "nationalities3.39e-02    1.15e-03\n",
      "cabinet     2.69e-02    2.30e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "cotrupis    2.15e-02    2.76e-03\n",
      "arignar     2.08e-02    1.55e-03\n",
      "arteriocyte 1.90e-02    1.46e-03\n",
      "appropriated1.80e-02    9.69e-04\n",
      "holistic    1.69e-02    1.51e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 10: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "saraste     1.37e-01    6.78e-03\n",
      "mccarthyism 6.21e-02    7.84e-03\n",
      "moiseenko   4.17e-02    1.74e-03\n",
      "thirteenthplace3.91e-02    3.67e-03\n",
      "nassar      3.23e-02    7.92e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 11: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "2010his     4.17e-02    2.15e-03\n",
      "sick        3.85e-02    7.99e-04\n",
      "theos       3.30e-02    1.27e-03\n",
      "monoclonal  2.31e-02    2.08e-03\n",
      "wellhanson  2.11e-02    1.76e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 12: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "sebastien   1.13e-01    8.91e-03\n",
      "covervilleibbott6.40e-02    5.53e-03\n",
      "contributions4.00e-02    4.70e-03\n",
      "silberman   3.63e-02    3.37e-03\n",
      "fusing      3.47e-02    5.19e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 13: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "occasionsoriginally9.60e-02    9.97e-03\n",
      "brentano    9.28e-02    2.04e-02\n",
      "riku        8.30e-02    2.46e-02\n",
      "yogaat      6.11e-02    1.22e-02\n",
      "testingbut  4.47e-02    1.93e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 14: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "wiseaus     1.15e-01    5.53e-03\n",
      "cutler      1.03e-01    3.64e-03\n",
      "variants    5.10e-02    1.16e-03\n",
      "ska         4.71e-02    1.94e-03\n",
      "2005brunero 4.57e-02    6.25e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 15: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "producergenka9.90e-02    1.32e-02\n",
      "deter       5.98e-02    5.74e-03\n",
      "726         5.32e-02    1.39e-02\n",
      "newmedia    5.21e-02    8.68e-03\n",
      "paradoxically4.69e-02    7.80e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 16: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "fences      1.20e-01    9.69e-03\n",
      "fluke       8.51e-02    1.06e-02\n",
      "lilli       4.87e-02    7.44e-03\n",
      "blaze       4.70e-02    5.52e-03\n",
      "kwaniewskicurrently4.13e-02    9.88e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 17: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "chatted     1.30e-02    1.97e-04\n",
      "evon        1.19e-02    1.58e-03\n",
      "forged      1.07e-02    2.83e-04\n",
      "finkenzeller1.03e-02    5.77e-05\n",
      "verzweyveld 1.01e-02    2.24e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 18: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "nationalities1.12e-01    5.23e-03\n",
      "bullpenafter8.40e-02    9.74e-03\n",
      "ingluvin    5.39e-02    8.05e-03\n",
      "vedders     4.97e-02    7.52e-03\n",
      "upright     4.84e-02    1.30e-02\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 19: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          9.29e-02    8.21e-03\n",
      "bye         8.06e-02    6.81e-03\n",
      "macleodin   7.95e-02    2.83e-02\n",
      "distributor 6.87e-02    2.49e-02\n",
      "gazelle     5.87e-02    1.08e-02\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 20: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "19691976he  1.28e-01    7.34e-03\n",
      "cleantech   4.89e-02    4.79e-03\n",
      "kstate      3.65e-02    2.00e-03\n",
      "halt        3.32e-02    1.33e-03\n",
      "deathlocally3.25e-02    3.34e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 21: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "remarkably  5.64e-02    6.42e-03\n",
      "mcglothlin  4.04e-02    3.61e-03\n",
      "osagie      3.08e-02    2.28e-03\n",
      "servant     2.40e-02    1.07e-03\n",
      "dunfermline 2.38e-02    1.88e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 22: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "bedazzled   5.66e-02    7.14e-03\n",
      "knot        4.28e-02    1.66e-03\n",
      "leritz      3.92e-02    3.01e-03\n",
      "servant     3.67e-02    1.74e-03\n",
      "selvagem    3.52e-02    4.57e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 23: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "halt        6.80e-02    3.06e-03\n",
      "closed      6.29e-02    3.42e-03\n",
      "craigs      3.82e-02    1.24e-03\n",
      "nocne       3.56e-02    5.48e-03\n",
      "welldocumented3.18e-02    2.33e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 24: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "wnba        7.41e-02    4.96e-03\n",
      "panta       5.63e-02    4.27e-03\n",
      "nationalities4.36e-02    2.12e-03\n",
      "trademarkyevgeny3.28e-02    1.14e-03\n",
      "ghetto      2.34e-02    1.21e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf, out['means'], out['covs'], map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Model with random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "num_clusters = len(means)\n",
    "num_docs, num_words = tf_idf.shape\n",
    "\n",
    "random_means = []\n",
    "random_covs = []\n",
    "random_weights = []\n",
    "\n",
    "for k in range(num_clusters):\n",
    "    \n",
    "    # Create a numpy array of length num_words with random normally distributed values.\n",
    "    # Use the standard univariate normal distribution (mean 0, variance 1).\n",
    "    # YOUR CODE HERE\n",
    "    mean = np.random.normal(size = num_words)\n",
    "    \n",
    "    # Create a numpy array of length num_words with random values uniformly distributed between 1 and 5.\n",
    "    # YOUR CODE HERE\n",
    "    cov = np.random.uniform(1.,5.,size=num_words)\n",
    "\n",
    "    # Initially give each cluster equal weight.\n",
    "    # YOUR CODE HERE\n",
    "    weight = 1/num_clusters\n",
    "    \n",
    "    random_means.append(mean)\n",
    "    random_covs.append(cov)\n",
    "    random_weights.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(100282,)\n",
      "\n",
      "25\n",
      "\n",
      "25\n",
      "(100282,)\n"
     ]
    }
   ],
   "source": [
    "print(len(random_means))\n",
    "print(random_means[0].shape)\n",
    "print(\"\")\n",
    "\n",
    "print(len(random_weights))  # 25\n",
    "print(\"\")\n",
    "\n",
    "print(len(covs))\n",
    "print(covs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_random_init = EM_for_high_dimension(tf_idf, random_means, random_covs, random_weights, cov_smoothing=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-764085987.5730064,\n",
       " 2282866699.1732855,\n",
       " 2362585588.356494,\n",
       " 2362875609.1670547,\n",
       " 2362875609.1670547]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_random_init['loglik']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          4.21e-02    5.79e-03\n",
      "registration2.63e-02    1.82e-03\n",
      "nationalities2.03e-02    2.37e-03\n",
      "boylum      1.80e-02    5.72e-03\n",
      "motor       1.20e-02    1.82e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "finkenzeller1.38e-02    1.11e-04\n",
      "em          1.29e-02    1.67e-03\n",
      "sick        1.06e-02    3.19e-04\n",
      "nationalities1.05e-02    9.94e-04\n",
      "cutler      1.04e-02    9.58e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          3.30e-02    3.96e-03\n",
      "registration2.43e-02    2.57e-03\n",
      "nationalities1.46e-02    1.42e-03\n",
      "finkenzeller1.13e-02    1.20e-04\n",
      "mechanicsburg1.06e-02    2.02e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.69e-02    3.29e-03\n",
      "registration1.76e-02    1.50e-03\n",
      "knot        1.43e-02    2.01e-03\n",
      "murdoch     1.04e-02    5.20e-04\n",
      "finkenzeller1.00e-02    9.16e-05\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.59e-02    3.38e-03\n",
      "nationalities1.54e-02    1.69e-03\n",
      "registration1.47e-02    1.28e-03\n",
      "finkenzeller1.24e-02    1.13e-04\n",
      "sick        1.05e-02    2.92e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.73e-02    3.73e-03\n",
      "registration2.18e-02    2.47e-03\n",
      "cutler      2.15e-02    2.54e-03\n",
      "wiseaus     1.79e-02    2.28e-03\n",
      "testingbut  1.59e-02    9.47e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          3.16e-02    3.84e-03\n",
      "registration2.92e-02    3.00e-03\n",
      "saraste     1.87e-02    4.07e-03\n",
      "cutler      1.09e-02    1.05e-03\n",
      "bmxers      1.08e-02    3.75e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.67e-02    3.61e-03\n",
      "registration1.64e-02    1.50e-03\n",
      "sick        1.27e-02    4.92e-04\n",
      "gamesbesides1.14e-02    6.38e-03\n",
      "finkenzeller1.10e-02    1.04e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "cutler      2.46e-02    2.44e-03\n",
      "em          1.83e-02    2.55e-03\n",
      "testingbut  1.82e-02    1.25e-03\n",
      "cherogony   1.66e-02    9.01e-04\n",
      "brentano    1.65e-02    6.31e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.35e-02    2.81e-03\n",
      "registration1.70e-02    1.81e-03\n",
      "finkenzeller1.38e-02    1.23e-04\n",
      "sick        1.28e-02    3.66e-04\n",
      "19691976he  1.00e-02    1.21e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 10: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.82e-02    3.37e-03\n",
      "registration2.11e-02    1.96e-03\n",
      "theatersa   1.55e-02    6.60e-03\n",
      "gamewhile   1.39e-02    1.71e-03\n",
      "sick        1.33e-02    4.72e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 11: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          1.96e-02    2.49e-03\n",
      "registration1.49e-02    1.77e-03\n",
      "wnba        1.33e-02    1.98e-03\n",
      "nationalities1.30e-02    9.98e-04\n",
      "finkenzeller1.30e-02    1.11e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 12: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          3.42e-02    4.59e-03\n",
      "registration2.10e-02    1.98e-03\n",
      "knot        1.59e-02    2.26e-03\n",
      "finkenzeller1.20e-02    1.15e-04\n",
      "halt        1.15e-02    1.04e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 13: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          1.95e-02    3.20e-03\n",
      "finkenzeller1.27e-02    9.42e-05\n",
      "sick        1.27e-02    5.70e-04\n",
      "registration1.04e-02    9.32e-04\n",
      "sagardorr   9.84e-03    3.93e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 14: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "sebastien   2.41e-02    5.18e-03\n",
      "coverville  2.03e-02    6.13e-03\n",
      "macgill     1.94e-02    5.53e-03\n",
      "em          1.48e-02    2.05e-03\n",
      "panta       1.44e-02    1.93e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 15: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "cutler      1.63e-02    1.76e-03\n",
      "em          1.49e-02    2.10e-03\n",
      "finkenzeller1.35e-02    1.08e-04\n",
      "nationalities1.30e-02    1.10e-03\n",
      "testingbut  1.18e-02    8.20e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 16: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "knot        2.09e-02    3.65e-03\n",
      "monoclonal  1.26e-02    2.19e-03\n",
      "2010his     1.20e-02    1.17e-03\n",
      "nationalities1.19e-02    1.26e-03\n",
      "wiseaus     1.18e-02    2.13e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 17: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.87e-02    3.67e-03\n",
      "bullpenafter1.83e-02    4.74e-03\n",
      "ingluvin    1.71e-02    4.89e-03\n",
      "nationalities1.63e-02    1.25e-03\n",
      "registration1.54e-02    9.90e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 18: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.50e-02    4.52e-03\n",
      "nationalities2.05e-02    2.45e-03\n",
      "finkenzeller1.41e-02    1.33e-04\n",
      "dops        1.26e-02    2.12e-03\n",
      "knot        1.24e-02    1.67e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 19: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.62e-02    4.08e-03\n",
      "finkenzeller1.28e-02    1.20e-04\n",
      "registration1.22e-02    1.08e-03\n",
      "harnden     1.15e-02    4.49e-04\n",
      "amecatlel   1.13e-02    3.93e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 20: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          2.37e-02    4.14e-03\n",
      "byd         1.34e-02    3.64e-03\n",
      "registration1.16e-02    9.68e-04\n",
      "finkenzeller1.15e-02    9.46e-05\n",
      "buchenwald  1.13e-02    1.90e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 21: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "finkenzeller1.35e-02    9.19e-05\n",
      "sick        1.22e-02    3.46e-04\n",
      "em          1.19e-02    1.71e-03\n",
      "deter       9.61e-03    1.29e-03\n",
      "examinationspaulker9.58e-03    7.85e-05\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 22: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "fences      1.71e-02    3.31e-03\n",
      "em          1.51e-02    2.41e-03\n",
      "finkenzeller1.39e-02    1.05e-04\n",
      "registration1.19e-02    1.47e-03\n",
      "nationalities1.10e-02    1.27e-03\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 23: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          3.39e-02    5.30e-03\n",
      "registration2.08e-02    1.92e-03\n",
      "wnba        1.74e-02    3.15e-03\n",
      "nationalities1.52e-02    1.40e-03\n",
      "finkenzeller1.19e-02    1.22e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n",
      "Cluster 24: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "em          1.73e-02    2.63e-03\n",
      "uncontrollable1.36e-02    6.66e-04\n",
      "deter       1.31e-02    2.31e-03\n",
      "finkenzeller1.22e-02    9.16e-05\n",
      "testingbut  1.18e-02    7.78e-04\n",
      "\n",
      "=====================================================Quiz Question. Select all the topics that have a cluster in the model created above. [multiple choice]====\n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf, out_random_init['means'], out_random_init['covs'], map_index_to_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
