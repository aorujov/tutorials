{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_or_Dogs (Transfer Learning).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sSZwiQKZVpqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Notebook info:\n",
        "\n",
        "* Dataset - Cats or Dogs - 2k images\n",
        "* Network - Inception V3\n",
        "* Additional - Transfer learning\n",
        "\n",
        "\n",
        "\n",
        "**links:**\n",
        "* https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "* https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "2suVWyc9X8CA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the pre-trained model (transfer learning)"
      ]
    },
    {
      "metadata": {
        "id": "rfi9h7zfVWH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11394
        },
        "outputId": "cbe5a85e-fca6-410b-9765-e92a626e354e"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 16:43:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  99.8MB/s    in 0.8s    \n",
            "\n",
            "2019-04-25 16:43:44 (99.8 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qfJrg3niV-y7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "16ba819f-351e-40f1-c2c3-d0e2b3d6455e"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9emnFtDrXyl2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Getting the Data"
      ]
    },
    {
      "metadata": {
        "id": "-E9IhcEbWmaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "03062d7c-93fb-46cd-de26-90931a6e93b4"
      },
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-25 16:44:15--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  59.0MB/s    in 1.1s    \n",
            "\n",
            "2019-04-25 16:44:16 (59.0 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylDJnIdAYIVa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "sRsbc157YDvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1090
        },
        "outputId": "e01c2b5a-b4aa-42d6-8ec0-3c5b1291ae7c"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.4892 - acc: 0.8750\n",
            " - 20s - loss: 0.5151 - acc: 0.7395 - val_loss: 0.4892 - val_acc: 0.8750\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2229 - acc: 0.9450\n",
            " - 17s - loss: 0.3769 - acc: 0.8405 - val_loss: 0.2229 - val_acc: 0.9450\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4703 - acc: 0.9130\n",
            " - 17s - loss: 0.3580 - acc: 0.8410 - val_loss: 0.4703 - val_acc: 0.9130\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.3105 - acc: 0.9440\n",
            " - 19s - loss: 0.3214 - acc: 0.8650 - val_loss: 0.3105 - val_acc: 0.9440\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4517 - acc: 0.9270\n",
            " - 18s - loss: 0.3103 - acc: 0.8680 - val_loss: 0.4517 - val_acc: 0.9270\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.5491 - acc: 0.9100\n",
            " - 17s - loss: 0.3441 - acc: 0.8500 - val_loss: 0.5491 - val_acc: 0.9100\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4519 - acc: 0.9310\n",
            " - 18s - loss: 0.2640 - acc: 0.8910 - val_loss: 0.4519 - val_acc: 0.9310\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.3238 - acc: 0.9530\n",
            " - 18s - loss: 0.2996 - acc: 0.8670 - val_loss: 0.3238 - val_acc: 0.9530\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4226 - acc: 0.9390\n",
            " - 19s - loss: 0.3004 - acc: 0.8835 - val_loss: 0.4226 - val_acc: 0.9390\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4312 - acc: 0.9430\n",
            " - 17s - loss: 0.2677 - acc: 0.8900 - val_loss: 0.4312 - val_acc: 0.9430\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 0.4567 - acc: 0.9490\n",
            " - 18s - loss: 0.2599 - acc: 0.8935 - val_loss: 0.4567 - val_acc: 0.9490\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4811 - acc: 0.9410\n",
            " - 17s - loss: 0.2659 - acc: 0.8930 - val_loss: 0.4811 - val_acc: 0.9410\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.5006 - acc: 0.9400\n",
            " - 20s - loss: 0.2714 - acc: 0.8990 - val_loss: 0.5006 - val_acc: 0.9400\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.5194 - acc: 0.9400\n",
            " - 18s - loss: 0.2411 - acc: 0.9040 - val_loss: 0.5194 - val_acc: 0.9400\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.4019 - acc: 0.9490\n",
            " - 17s - loss: 0.2616 - acc: 0.8910 - val_loss: 0.4019 - val_acc: 0.9490\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.7227 - acc: 0.9190\n",
            " - 18s - loss: 0.2384 - acc: 0.8975 - val_loss: 0.7227 - val_acc: 0.9190\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.5020 - acc: 0.9390\n",
            " - 17s - loss: 0.2634 - acc: 0.8880 - val_loss: 0.5020 - val_acc: 0.9390\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.4065 - acc: 0.9530\n",
            " - 19s - loss: 0.2600 - acc: 0.8905 - val_loss: 0.4065 - val_acc: 0.9530\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.3630 - acc: 0.9550\n",
            " - 17s - loss: 0.2511 - acc: 0.9035 - val_loss: 0.3630 - val_acc: 0.9550\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.5728 - acc: 0.9360\n",
            " - 17s - loss: 0.2318 - acc: 0.9085 - val_loss: 0.5728 - val_acc: 0.9360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x-qeDFIQYOPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Results"
      ]
    },
    {
      "metadata": {
        "id": "ZxuGobz9YDsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ec32f3a3-b701-4d7f-9c04-fe654114812c"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sdxgYL8dYDp4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsdM0TvJYDnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYKRHue_YDkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3etYgIWYDXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8Hv4NFCYDUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}